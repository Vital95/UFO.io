sRes <- deviance(fit)
1 - sRes/sTot
summary(fit)$r.squared
cor(galton$child, galton$parent)
cor(galton$child, galton$parent) ^2
ones <- rep(1, nrow(galton))
lm(child~ones + parent - 1, galton)
lm(child~ parent, galton)
im(child ~ 1, galton)
lm(child ~ 1, galton)
head(trees)
fit <- lm(Volume ~ Girth ~ Height + Constant - 1, trees)
fit <- lm(Volume ~ Girth ~ Height + Constant - 1, trees)
fit <- lm(Volume ~ Girth ~ Height - 1, trees)
fit <- lm(Volume ~ Girth + Height + Constant -1, trees)
trees2 <- eliminate("Girth", trees)
View(trees)
View(trees2)
fit2 <- lm(Volume ~ Height + Constant -1, trees2)
lapply(list(fit, fit2), coef)
lm(., swiss)
lm(".", swiss)
lm("all", swiss)
lm(all ~ ., swiss)
lm( ~ ., swiss)
lm(. ~ ., swiss)
names(swiss)
lm(Fertility ~ ., swiss)
all <-  lm(Fertility ~ ., swiss)
summary(all)
all <-  lm(Fertility ~ Agriculture, swiss)
summary(lm(Fertility ~ Agriculture, swiss))
cor(swiss$Education, swiss$Examination)
cor(swiss$Agriculture, swiss$Education)
makelms()
ec <- swiss$Examination + swiss$Catholic
ec <- sum(swiss$Examination + swiss$Catholic)
efit <- lm(Fertility ~ . + ec, swiss)
all$coefficients - efit$coefficients
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
summary(lm(x ~ y))
data < lm(x ~ y)
names(lm(x ~ y))
lm(x ~ y)$residuals
lm(x ~ y)$df.residuals
lm(x ~ y)$df.residual
mean(lm(x ~ y)$residuals) / 9
fit <- lm(w ~ mpg, data = mtcars )
fit <- lm(w ~ mpg, data = mtcars)
names(mtcars)
fit <- lm(wt ~ mpg, data = mtcars)
confint(fit, "wt", level = 0.95)
y <- mtcars$mpg
x <- mtcars$wt
fit_car <- lm(y ~ x)
predict(fit_car, newdata = data.frame(x = mean(x)), interval = ("confidence"))
yhat <- fit_car$coef[1] + fit_car$coef[2] * mean(x)
yhat + c(-1, 1) * qt(.975, df = fit_car$df) * summary(fit_car)$sigma / sqrt(length(y))
summary(fit_car)
help(mtcars)
y <- mtcars$mpg
x <- mtcars$wt
fit_car <- lm(y ~ x)
predict(fit_car, newdata = data.frame(x = 3000)), interval = ("confidence"))
y <- mtcars$mpg
x <- mtcars$wt
fit_car <- lm(y ~ x)
predict(fit_car, newdata = data.frame(3000)), interval = ("confidence"))
y <- mtcars$mpg
x <- mtcars$wt
fit_car <- lm(y ~ x)
predict(fit_car, newdata = 3000, interval = ("confidence"))
y <- mtcars$mpg
x <- mtcars$wt
fit_car <- lm(y ~ x)
predict(fit_car, newdata = data.frame(x =3), interval = ("prediction"))
y <- mtcars$mpg
x <- mtcars$wt
fit_car <- lm(y ~ x)
predict(fit_car, newdata = data.frame(x =1 * 2), interval = ("prediction"))
fit_car2 <- lm(y ~ I(x/2))
sumCoef2 <- coef(summary(fit_car2))
(sumCoef2[2,1] + c(-1, 1) * qt(.975, df = fit_car2$df) * sumCoef2[2, 2])
fit_car <- lm(y ~ x)
names(fit_car)
fit_car$qr
library(swirl)
Swirl()
swirl()
install.packages(car)
install.packages(minqa)
install.packages("minqa")
install.packages("car")
install.packages("nloptr")
install.packages("RcppEigen")
install.packages("lme4")
install.packages("SparseM")
install.packages("MatrixModels")
install.packages("pbkrtest")
install.packages("quantreg")
library(swirl)
swirl()
x1c <- simbias()
apply(x1c, 1, mean)
fit1 <- lm(Fertility ~ Agriculture, data = swiss)
fit3 <- lm(Fertility ~ Agriculture + Examination + Education, data = swiss)
anova(fit1, fit3)
deviance(fit3)
d <- deviance(fit3)/43
n <- (deviance(fit1) - deviance(fit3))/2
n/d
pf(n/d, 2, 42, lower.tail = FALSE)
pf(n/d, 2, 43, lower.tail = FALSE)
shapiro.test(fit3$residuals)
anova(fit1, fit3, fit5, fit6)
ravenData
mdl <- glm(ravenWinNum ~ ravenScore, family = binomial,data = ravenData)
lodds <- predict(mdl, data.frame(ravenScore=c(0, 3, 6)))
exp(lodds)/(1+exp(lodds))
summary(mdl)
confint(mdl)
exp(confint(mdl))
anova(mdl)
qchisq(0.95, 1)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
library("AppliedPredictiveModeling")
install.packages("AppliedPredictiveModeling")
library("AppliedPredictiveModeling")
data(AlzheimerDisease)
adData = data.frame(predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
install.packages("caret")
library("caret")
adData = data.frame(predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
summary(concrete)
library(ggplot2)
fit1 <- lm(CompressiveStrength ~ ., data = concrete)
plot(concrete)
ggplot(concrete) +
geom_point() + stat_smooth(method = "lm", col = "red")
library(GGally)
install.packages(GGally)
install.packages("GGally")
ggpairs(concrete) + stat_smooth(method = "lm", col = "red")
library(GGally)
ggpairs(concrete) + stat_smooth(method = "lm", col = "red")
scatterplot.matrix(~.|CompressiveStrength, data=concrete,
main="plot")
library(car)
scatterplot.matrix(~.|CompressiveStrength, data=concrete,
main="plot")
hist(concrete$Superplasticizer)
hist(log10(concrete$Superplasticizer)
hist(log10(concrete$Superplasticizer))
hist(log10(concrete$Superplasticizer + 1))
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
IL_col_idx <- grep("^[Ii][Ll].*", names(training))
preObj <- preProcess(training[, IL_col_idx], method=c("center", "scale", "pca"), thresh=0.9)
preObj
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
IL_col_idx <- grep("^[Ii][Ll].*", names(training))
suppressMessages(library(dplyr))
new_training <- training[, c(names(training)[IL_col_idx], "diagnosis")]
names(new_training)
IL_col_idx <- grep("^[Ii][Ll].*", names(testing))
suppressMessages(library(dplyr))
new_testing <- testing[, c(names(testing)[IL_col_idx], "diagnosis")]
names(new_testing)
non_pca_model <- train(diagnosis ~ ., data=new_training, method="glm")
install.packages("e1071")
non_pca_model <- train(diagnosis ~ ., data=new_training, method="glm")
non_pca_result <- confusionMatrix(new_testing[, 13], predict(non_pca_model, new_testing[, -13]))
non_pca_result
pc_training_obj <- preProcess(new_training[, -13], method=c('center', 'scale', 'pca'), thresh=0.8)
pc_training_preds <- predict(pc_training_obj, new_training[, -13])
pc_testing_preds <- predict(pc_training_obj, new_testing[, -13])
# compute the model with pca predictors
pca_model <- train(new_training$diagnosis ~ ., data=pc_training_preds, method="glm")
# apply the PCA model on the testing set
pca_result <- confusionMatrix(new_testing[, 13], predict(pca_model, pc_testing_preds))
pca_result
pca_model <- train(new_training$diagnosis ~ ., data=pc_training_preds, method="glm")
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
library("ElemStatLearn")
install.packages("AppliedPredictiveModeling")
install.packages("caret")
install.packages("ElemStatLearn")
install.packages("pgmm")
install.packages("rpart")
install.packages("gbm")
install.packages("lubridate")
install.packages("forecast")
install.packages("e1071")
library(AppliedPredictiveModeling)
library(caret)
library(ElemStatLearn)
library(pgmm)
library(rpart)
library(gbm)
install.packages("survival")
install.packages("survival")
library(gbm)
library(lubridate)
library(forecast)
library(e1071)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
data(vowel.train)
data(vowel.test)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
View(vowel.train)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
RFfit <- train(y~ .,data=vowel.train,method="rf")
library(caret)
RFfit <- train(y~ .,data=vowel.train,method="rf")
RFfit <- train(y~ .,data=vowel.train,method="rf")
RFpred <- predict(RFfit,vowel.test)
confusionMatrix(RFpred,vowel.test$y)$overall['Accuracy']
Bofit <- train(y~ .,data=vowel.train,method="gbm",verbose=FALSE)
Bofit <- train(y~ .,data=vowel.train,method="gbm",verbose=FALSE)
Bopred <- predict(RFfit,vowel.test)
confusionMatrix(Bopred,vowel.test$y)$overall['Accuracy']
aa <- RFpred == Bopred
bb <- vowel.test$y== RFpred
sum(aa*bb)/sum(aa)
set.seed(33833)
RFfit <- train(y~ .,data=vowel.train,method="rf")
RFpred <- predict(RFfit,vowel.test)
confusionMatrix(RFpred,vowel.test$y)$overall['Accuracy']
set.seed(33833)
Bofit <- train(y~ .,data=vowel.train,method="gbm",verbose=FALSE)
Bopred <- predict(RFfit,vowel.test)
confusionMatrix(Bopred,vowel.test$y)$overall['Accuracy']
aa <- RFpred == Bopred
bb <- vowel.test$y== RFpred
sum(aa*bb)/sum(aa)
set.seed(33833)
Bofit <- train(y~ .,data=vowel.train,method="gbm",verbose=FALSE)
Bopred <- predict(RFfit,vowel.test)
confusionMatrix(Bopred,vowel.test$y)$overall['Accuracy']
x -> 5
x = 5
5 -> x
x
y = 7
y
5 -> y
y
str <- readline()
UFO <- read.csv("UOF.txt")
setwd(str)
UFO <- read.csv("UOF.txt")
getwd()
UFO <- read.csv("UOF.txt")
UFO <- read.csv("UFO.txt")
View(UFO)
UFO <- read.csv("UFO.txt", header = FALSE)
View(UFO)
install.packages("plotly")
library(plotly)
header <- c("time","city","state","country","shape","length_of_encounter_seconds","described_duration _of_encounter","description","date_documented","latitude","longitude")
names(UFO) <- header
View(UFO)
UFOCleaned <- UFO[,c(1,5,6,10,11)]
View(UFOCleaned)
UFOCleaned$time <- substring(UFOCleaned$time,7,10)
View(UFOCleaned)
unique(UFOCleaned$time)
UFOCleaned <- UFO[,c(1,5,6,10,11)]
unique(UFOCleaned$time)
UFOCleaned$time <- as.Date(UFOCleaned$time)
View(UFOCleaned)
UFOCleaned <- UFO[,c(1,5,6,10,11)]
library(lubridate)
UFOCleaned <- UFO[,c(1,5,6,10,11)]
UFOCleaned$time <- mdy(UFOCleaned$time)
UFOCleaned$time <- year(UFOCleaned$time)
View(UFOCleaned)
UFOCleaned <- UFO[,c(1,5,6,10,11)]
View(UFOCleaned)
UFOCleaned$time <- year(UFOCleaned$time)
UFOCleaned <- UFO[,c(1,5,6,10,11)]
UFOCleaned$time <-as.Date(UFOCleaned$time,"%d/%m/%Y")
unique(UFOCleaned$time)
UFOCleaned <- UFO[,c(1,5,6,10,11)]
View(UFOCleaned)
UFOCleaned$time <-as.Date(UFOCleaned$time,"%d/%m/%Y")
View(UFOCleaned)
UFOCleaned <- UFO[,c(1,5,6,10,11)]
View(UFOCleaned)
tmp <- "11/17/2009 19:30"
as.Date(tmp,"%d/%m/%Y")
as.Date(tmp,"%d/%m/%Y ")
UFOCleaned <- UFO[,c(1,5,6,10,11)]
UFOCleaned$time <- as.character(UFOCleaned$time)
UFOCleaned$time <-as.Date(UFOCleaned$time,"%d/%m/%Y")
View(UFOCleaned)
UFOCleaned <- UFO[,c(1,5,6,10,11)]
tmp <- "11/13/1953 20:00"
as.Date(tmp,"%d/%m/%Y ")
UFOCleaned <- UFO[,c(1,5,6,10,11)]
UFOCleaned$time <- as.character(UFOCleaned$time)
UFOCleaned$time <-as.Date(UFOCleaned$time,"%d/%m/%Y %h:%m")
View(UFOCleaned)
tmp <- "11/13/1953 20:00"
tmp
as.Date(tmp,"%m/%d/%Y %h:%m")
as.Date(tmp,"%m/%d/%Y")
UFOCleaned <- UFO[,c(1,5,6,10,11)]
UFOCleaned$time <- as.character(UFOCleaned$time)
UFOCleaned$time <-as.Date(UFOCleaned$time,"%m/%d/%Y")
View(UFOCleaned)
UFOCleaned$time <-year(UFOCleaned$time)
View(UFOCleaned)
unique(UFOCleaned$time)
View(UFOCleaned)
View(UFOCleaned)
table(UFOCleaned)
table(UFOCleaned$time)
table(UFOCleaned$shape)
table(UFOCleaned$length_of_encounter_seconds)
UFOCleaned[complete.cases(UFOCleaned), ]
UFOCleaned <- UFOCleaned[complete.cases(UFOCleaned), ]
View(UFOCleaned)
g <- list(
scope = 'north america',
showland = TRUE,
landcolor = toRGB("grey83"),
subunitcolor = toRGB("white"),
countrycolor = toRGB("white"),
showlakes = TRUE,
lakecolor = toRGB("white"),
showsubunits = TRUE,
showcountries = TRUE,
resolution = 50,
projection = list(
type = 'conic conformal',
rotation = list(lon = -100)
),
lonaxis = list(
showgrid = TRUE,
gridwidth = 0.5,
range = c(-140, -55),
dtick = 5
),
lataxis = list(
showgrid = TRUE,
gridwidth = 0.5,
range = c(20, 60),
dtick = 5
)
)
p <- plot_geo(UFOCleaned, lat = ~latitude, lon = ~longitude, color = ~length_of_encounter_seconds) %>%
add_markers(
text = ~paste(UFOCleaned$length_of_encounter_seconds, "seconds"), hoverinfo = "text"
) %>%
layout(title = 'UFO encounters duretion ', geo = g)
p
p <- plot_geo(UFOCleaned, lat = ~latitude, lon = ~longitude, color = ~length_of_encounter_seconds) %>%
layout(title = 'UFO encounters duretion ', geo = g)
p
g <- list(
scope = 'north america',
showland = TRUE,
landcolor = toRGB("grey83"),
subunitcolor = toRGB("white"),
countrycolor = toRGB("white"),
showlakes = TRUE,
lakecolor = toRGB("white"),
showsubunits = TRUE,
showcountries = TRUE,
resolution = 50,
projection = list(
type = 'conic conformal',
rotation = list(lon = -100)
),
lonaxis = list(
showgrid = TRUE,
gridwidth = 0.5,
range = c(-140, -55),
dtick = 5
),
lataxis = list(
showgrid = TRUE,
gridwidth = 0.5,
range = c(20, 60),
dtick = 5
)
)
g <- list(
scope = 'north america',
showland = TRUE,
landcolor = toRGB("grey83"),
subunitcolor = toRGB("white"),
countrycolor = toRGB("white"),
showlakes = TRUE,
lakecolor = toRGB("white"),
showsubunits = TRUE,
showcountries = TRUE,
resolution = 50,
projection = list(
type = 'conic conformal',
rotation = list(lon = -100)
),
lonaxis = list(
showgrid = TRUE,
gridwidth = 0.5,
range = c(-140, -55),
dtick = 5
),
lataxis = list(
showgrid = TRUE,
gridwidth = 0.5,
range = c(20, 60),
dtick = 5
)
)
p <- plot_geo(UFOCleaned, lat = ~latitude, lon = ~longitude, color = ~length_of_encounter_seconds) %>%
layout(title = 'UFO encounters duretion ', geo = g)
p
p <- UFOCleaned %>%
plot_mapbox(lat = ~latitude, lon = ~longitude,
split = ~shape, size=2,
mode = 'scattermapbox', hoverinfo='name') %>%
layout(title = 'UFO encounters distribution by shape',
font = list(color='white'),
plot_bgcolor = '#191A1A', paper_bgcolor = '#191A1A',
mapbox = list(style = 'dark'),
legend = list(orientation = 'h',
font = list(size = 8)),
margin = list(l = 25, r = 25,
b = 25, t = 25,
pad = 2))
p
p <- UFOCleaned %>%
plot_mapbox(lat = ~latitude, lon = ~longitude,
split = ~shape, size=2,
mode = 'scattermapbox', hoverinfo='name') %>%
layout(title = 'UFO encounters distribution by shape',
font = list(color='white'),
plot_bgcolor = '#191A1A', paper_bgcolor = '#191A1A',
mapbox = list(style = 'dark'),
legend = list(orientation = 'h',
font = list(size = 8)),
margin = list(l = 25, r = 25,
b = 25, t = 25,
pad = 2))
p <- UFOCleaned %>%
plot_mapbox(lat = ~latitude, lon = ~longitude,
split = ~shape, size=2,
mode = 'scattermapbox', hoverinfo='name') %>%
layout(title = 'UFO encounters distribution by shape',
font = list(color='white'),
plot_bgcolor = '#191A1A', paper_bgcolor = '#191A1A',
mapbox = list(style = 'dark'),
legend = list(orientation = 'h',
font = list(size = 8)),
margin = list(l = 25, r = 25,
b = 25, t = 25,
pad = 2))
